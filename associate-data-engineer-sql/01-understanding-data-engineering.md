# Understanding Data Engineering

## About the Course

Conceptual course

No coding involved

## Objectives

- Being able to exchange with data engineers
- Provide a solid foundation to learn more

## Chapter 1: What is Data Engineering?

### Topics Covered
1. Data engineering and big data
2. Data engineers vs. data scientists
3. Data pipelines

### How Data Flows (Data Workflow)
1. Data collection and storage
2. Data preparation
3. Exploration and visualization
4. Experimentation & prediction

Data engineers are responsible for step 1.

### Data Engineers
They deliver data in the right form, correct data to right people as efficiently as possible. They:
- Ingest data from different sources
- Optimize databases for analysis
- Remove corrupted data
- Develop, construct, test, and maintain data architectures

As big data becomes the norm, more data engineers are needed.

### The 5 V's of Big Data
1. **Volume** - how much
2. **Variety** - what kind
3. **Velocity** - how frequent
4. **Veracity** - how accurate
5. **Value** - how useful

### Data Engineers vs Data Scientists

| Data Engineer        | Data Scientist    |
| -------------------- | ----------------- |
| Ingest, store data   | Exploit data      |
| Setup databases      | Access databases  |
| Build data pipelines | Analyze data      |

### The Data Pipeline
We Ingest, Process, Store - to do that we need pipelines. They:
- Automate the flow
- Ensure an efficient flow of data
- Extract, Transform, Validate, Load

**ETL Process:**
1. **Extract** data
2. **Transform** data
3. **Load** data

## Chapter 2: Data Structure

### Topics Covered
1. Structured vs. unstructured data
2. SQL
3. Data warehouse and data lakes

### Structured Data
- Easy to search and organize
- Consistent
- Defined types
- Can be grouped
- Stored in relational databases

## Chapter 3: How to Move and Process Data

### Topics Covered
1. Processing data
2. Scheduling data
3. Parallel computing
4. Cloud computing

---

*Notes compiled from DataCamp's Understanding Data Engineering course*
